[{"id":0,"href":"/hydra-blog/docs/what-is-hydra/","title":"about","section":"Docs","content":" What is Hydra? # Hydra is live code-able video synth and coding environment that runs directly in the browser. It is free and open-source and made for beginners and experts alike. You can simply open the hydra web editor on a laptop or mobile device to get started.\nHydra is written in JavaScript and compiles to WebGL under the hood. The syntax is inspired by analog modular synthesis, in which chaining or patching a set of transformations together generates a visual result.\nHydra can be used: # to mix and add effects to camera feeds, screenshares, live streams, and videos to create generative and audio-reactive visuals, and share them online with others in combination with other javascript libraries such as P5.js, Tone.js, THREE.js, or gibber to add interactive video effects to a website to experiment with and learn about video feedback, fractals, and pixel operations to stream video between browsers and live-jam with others online Further resources and next steps # For more information and instructions, see: Getting Started, a list of hydra functions, the community database of projects and tutorials, a gallery of user-generated sketches, and the source code on github.\nHydra was created by olivia jack and is supported by a community of contributers. If you enjoy using Hydra, please consider supporting continued development.\nNext: Getting Started\n"},{"id":1,"href":"/hydra-blog/docs/learning/getting-started-short/","title":"getting started","section":"learning","content":" Getting started # Play with gallery examples # The simplest way to get started with hydra is to play around with the example sketches in the web editor.\nTo get started, open the the hydra web editor in a separate window. Close the top window by clicking the [x] in the top right.\nYou will see some colorful visuals in the background with text on top. The text is code that generates the visuals behind it.\nYou can change the hydra sketch shown on the screen by clicking the shuffle button.\nChange some numbers # Change values that appears on Hydra web editor at the sketch examples to see what happens. Values can have decimal numbers, is recommended not using big values inside the parentheses. Numbers must be inside the parentheses. Every Hydra code starts by generating an input signal source and ends with an output buffer. Adding a value inside or after .out() won\u0026rsquo;t work.\nosc(10,0.1,0.5).color(1,0.895,0.55).out() Run your code # Use the triangle \u0026ldquo;run\u0026rdquo; button to run your code. Hint: you can also run the code by typing ctrl+shift+enter.\nHave fun! # :)\n"},{"id":2,"href":"/hydra-blog/docs/learning/","title":"learning","section":"Docs","content":" learning # getting started # video synth basics # overview of hydra\u0026rsquo;s modular approach and main function types: sources, geometry, color, blending, and modulation\nexternal sources # using webcams, images, videos, html canvas elements, and live streams inside a hydra sketch\nsequencing and interactivity # Making dynamic and interactive sketches using arrays, custom functions, audio reactivity, mouse input, and MIDI controllers.\nweb editor # key commands, comments, saving sketches, loading extensions and external libraries, publishing to the gallery\nsynth configuration # how to change the speed, bpm, and resolution of a hydra instance, as well as write custom glsl functions\nhow-to # a quick reference for common questions\nguides # deeper dives into hydra topics written by members of the community.\n"},{"id":3,"href":"/hydra-blog/docs/reference/","title":"reference","section":"Docs","content":""},{"id":4,"href":"/hydra-blog/docs/learning/video-synth-basics/","title":"video synth basics","section":"learning","content":" Modular Video Synth Basics # Hydra is inspired by modular synthesis. Instead of connecting cables you connect different kinds of javascript functions.\nsource Sandin Image Processor # Press the run button to run this code and update the visuals on the screen. You should see some scrolling stripes appear in the background.\nThis creates a visual oscillator. Try modifying the parameters of the oscillator by putting a number inside the parentheses of osc(), for example osc(10).out().\nRe-run the code by pressing the run button again, and seeing the visuals update. Try adding other values to control the oscillator\u0026rsquo;s frequency, sync, and color offset.\nTrick: you can also use the keyboard shortcut ‘ctrl + shift + enter’ to have the same effect as the run button.\nAdding transformations # We can add another transformation to the oscillator from above, by adding the function rotate() after the oscillator:\nAs you can see, you have first an input source osc() and things that come after (rotate() and out()) are connected with a dot ‘.’ In this sense,\nYou can continue adding transformations to this chain of functions. For example:\nRepeat:\nFor more available sources and transformations, see the interactive function reference. The logic is to start with a source (such as osc(), shape(), or noise()), and then add transformations to geometry and color (such as .rotate(), .kaleid(), .pixelate() ), and in the end always connect the chain of transformations to the output screen .out() .\nWhat is an error? # Sometimes, you will try to run a line of code, and nothing will happen. If you have an error you’ll notice text in red at the left-bottom on your screen. Something like ‘Unexpected token ‘.’ (in red) will appear. This doesn’t affect your code, but you won’t be able to continue coding until you fix the error. Usually it is a typing error or something related to the syntax.\nWhat is a comment? # // Hello I’m a comment line. I’m a text that won’t change your code. You can write notations, your name or even a poem here. Multiple outputs # By default, hydra contains four separate virtual outputs that can each render different visuals, and can be mixed with each other to create more complex visuals. The variables o0, o1, o2, and o3 correspond to the different outputs.\nTo see all four of the outputs at once, use the render() function. This will divide the screen into four, showing each output in a different section of the screen.\nUsing a different variable inside the .out() function renders the chain to a different output. For example, .out(o1) will render a function chain to graphics buffer o1.\nBy default, only output o0 is rendered to the screen, while the render() command divides the screen in four. Show a specific output on the screen by adding it inside of render(), for example render(o2) to show buffer o2.\nTrick: try to create different sketches and switch them in your live performance or even combine them.\nBlending multiple visual sources together # You can use blend functions to combine multiple visual sources. .blend() combines the colors from two sources to create a third source.\nTry adding transformations to the above sources (such as osc(10).rotate(0, 0.1).out(o1)) to see how it affects the combined image. You can also specify the amount of blending by adding a separate parameter to .blend(), for example .blend(o1, 0.9).\nThere are multiple blend modes in hydra, similar to blend modes you might find in a graphics program such as photoshop or gimp. See the function reference for more possibilities.\nModulation # While blend functions combine the colors from two visual sources, modulate functions use the colors from one source to affect the geometry of the second source. This creates a sort of warping or distorting effect. An analogy in the real world would be looking through a texture glass window. modulate() does not change color or luminosity but distorts one visual source using another visual source.\nUsing the same sources from above, we can use an oscillator to modulate or warp the camera image:\nYou can add a second parameter to the modulate() function to control the amount of warping: modulate(o1, 0.9). In this case, the red and green channels of the oscillator are being converted to x and y displacement of the camera image.\nAll geometry transformations have corresponding modulate functions that allow you to use one source to warp another source. For example, .modulateRotate() is similar to .rotate(), but it allows you to apply different amounts of rotation to different parts of the visual source. See the function reference for more examples.\nMore blending and modulating # In addition to using multiple outputs to combine visuals, you can also combine multiple sources within the same function chain, without rendering them to separate outputs.\nThis allows you to use many sources, blend modes, and modulation, all from within the same chain of functions.\nTrick: use ctrl + shift + f from the web editor to auto-format your code\nModulating with the camera # We have now covered all of the basic types of functions within hydra: source, geometry, color, blending, and modulation! See what you can come up with by mixing these together.\nHave fun! # "},{"id":5,"href":"/hydra-blog/posts/hello-world/","title":"Brand new hydra blog and documentation portal","section":"blog","content":"WIP portal for hydra video synth. This will be a home for news and updates regarding hydra, as well as a hub for community resources and documentaiton.\nFor the main hydra website, see the web editor.\nWe welcome contributions!\n"},{"id":6,"href":"/hydra-blog/docs/learning/external-sources/","title":"external sources: cameras, videos, streams","section":"learning","content":" External Sources # Using the webcam # In addition to using sources from within hydra (such as osc() and shape()), you can use hydra to process external video sources such as a webcam. To initialize the webcam, run the following code:\ns0.initCam() This activates the webcam source inside a variable called s0, and you should see the light on your webcam light up. However, you will still not see the webcam image on the screen. In order to use the camera within a hydra sketch, you need to use it within the src() function.\nSimilar to adding transformations above, you can add transformations of color and geometry to the camera output, by adding functions to the chain:\nIf you have multiple webcams, you can access separate cameras by adding a number inside initCam, for example s0.initCam(1) or s0.initCam(2).\ninitCam # You can use a webcam\u0026rsquo;s video as such:\ns0.initCam() s0.initCam(2) // if you have many cameras, you can select one specifically initScreen # You can capture your screen or specific windows or tabs to use as a video source:\ns0.initScreen() initImage # In order to load an image to load an image into a source object, the syntax is the following:\ns0.initImage(\u0026#34;https://www.somewebpage.org/urlto/image.jpg\u0026#34;) When running Hydra in Atom, or any other local manner, you can load local files referring to them by URI:\ns0.initImage(\u0026#34;file:///home/user/Images/image.png\u0026#34;) Supported formats # You can load .jpeg, .png, and .bmp as well as .gif and .webp (although animation won\u0026rsquo;t work).\ninitVideo # The syntax for loading video is the same as for loading image, only changing the function to loadVideo:\ns0.initVideo(\u0026#34;https://www.somewebpage.org/urlto/video.mp4\u0026#34;) Supported formats # You can load .mp4, .ogg and .webm videos.\nUseful HTML Video properties # You can access all of the HTML Video functions when a video is loaded to a Source via s0.src. Some useful properties are:\ns0.src.playbackRate = 2 // double the speed at which the video plays s0.src.currentTime = 10 // seek to the 10th second s0.src.loop = false // don\u0026#39;t loop the video initStream : streaming between Hydra sessions # Hydra (the editor) also has built-in streaming. You can stream the output of your Hydra to someone else and vice-versa. This is done in a similar fashion to using images and videos, using external sources. But there are some extra steps for streaming:\nThe pb object # On your Hydra editor, you can find a pre-defined object called pb (as in patch-bay). This object basically represents the connection of your Hydra editor instance to all others hosted on the same server. When you want to share your stream to someone else you\u0026rsquo;ll have to give your Hydra session a name. Do this using the pb.setName() function and by passing in some string as the name. For example: pb.setName('myverycoolsession'). If you want someone else to stream to you, ask them to set a name as such and share it with you.\nYou can see online sessions using the function pb.list(), which will return an Array of names.\nStarting to stream # Streaming is as simple as initiating the source as a stream and passing the name of the session you want to stream. For example:\ns0.initStream(\u0026#39;myfriendsverycoolsession\u0026#39;) src(s0) .out() Extra parameters # Any external sources loaded into Hydra are using regl\u0026rsquo;s texture constructor in the background. There are many properties you can set when loading a texture and Hydra and regl handle the important ones for you. But to set any of these properties you can pass an object containing them to any of the init functions. For example:\ns0.initCam(0,{mag: \u0026#39;linear\u0026#39;}) mag \u0026amp; min are the most used, since using linear interpolation will resize textures in a smooth way. The default for both is nearest.\nCommon problems # CORS policy # If you try to load images (or videos) from some websites (most of them, really), sometimes nothing shows up on the screen. Opening the browser\u0026rsquo;s console might reveal a message similar to this one:\nAccess to image at \u0026#39;...\u0026#39; from origin \u0026#39;https://hydra.ojack.xyz\u0026#39; has been blocked by CORS policy: No \u0026#39;Access-Control-Allow-Origin\u0026#39; header is present on the requested resource. The CORS in CORS policy stands for \u0026lsquo;Cross-origin resource sharing\u0026rsquo;. This refers to the action of calling resources (such as images) from one website to another. For example, asking for an image hosted on other website from inside the Hydra editor. This error message is basically telling us \u0026ldquo;hey, the website you\u0026rsquo;re trying to ask for an image doesn\u0026rsquo;t allow other websites to use their resources, so i can\u0026rsquo;t let you have that picture\u0026rdquo;. In order to circumvent this error, you can try re-uploading the images you want to use to some image hosting service that allows cross-origin sharing such as imgur, where you can also load short videos. You can also try to use websites which you know will allow cross-origin resource sharing such as Wikimedia Commons, which is great for video.\nLoading video from YouTube, Vimeo, etc # Some users may be tempted to try and load some video they liked on YouTube, for example, and run something suchlike:\ns0.initVideo(\u0026#39;https://www.youtube.com/watch?v=dQw4w9WgXcQ\u0026#39;) // doesn\u0026#39;t work This will not work. The same goes for Vimeo and other video streaming services. When you use such an URL, it is not returning a video, it is returning the website where you can watch the video! The URL you pass to initVideo has to go directly to a video file. In other words, the URL should (usually) end in .mp4, .webm or .ogg. And, even if you did get a URL directly to the video with a tool such as youtube-dl, you\u0026rsquo;ll run into CORS problems.\nWorkaround # The most common workarounds are:\nRun Hydra locally (on Atom for example) and load local video files Have the video run on its own window and use initScreen to capture it "},{"id":7,"href":"/hydra-blog/docs/learning/interactivity/","title":"sequencing \u0026 interactivity","section":"learning","content":" Sequencing and Interactivity # If you\u0026rsquo;re coding in Hydra, you\u0026rsquo;re constantly trying many values to input to the sources and transforms, and it\u0026rsquo;s just a matter of time until you like how more than one looks, and you want to somehow switch between them. We\u0026rsquo;ll be referring to this idea of arguments whose value change over time as dynamic arguments. And there are two main ways to achieve this in Hydra: Arrays and functions.\nSequencing using Arrays # Sequence your inputs # When you send an Array as an input, Hydra will automatically switch and jump from each element from the Array to the next one. When there are no more elements, it wraps all the way back to the beginning. Let\u0026rsquo;s see it in action:\nAs you can see, the fact that both these Arrays have a different amount of values doesn\u0026rsquo;t matter, Hydra will take values from each element of any Array for the same amount of time by default.\nChanging the speed of a specific Array # Hydra adds a couple of methods to all Arrays to be used inside Hydra. .fast will control the speed at which Hydra takes elements from the Array. It receives a Number as argument, by which the global speed will be multiplied. So calling .fast(1) on an Array is the same as nothing. Higher values will generate faster switching, while lower than 1 values will be slower.\nOffsetting the timing of an Array # Another one of the methods Hydra adds to Arrays, allows you to offset the timing at which Hydra will switch from one element of the Array to the next one. The method .offset takes a Number from 0 to 1.\nFitting the values of an Array within a range # Sometimes you have an Array whose values aren\u0026rsquo;t very useful when used as input for a some Hydra function. Hydra adds a .fit method to Arrays which takes a minimum and a maximum to which fit the values into:\nInterpolating between values # You can also interpolate between values instead of jumping from one to the other. That is, smoothly transition between values. For this you can use the .smooth method. It may take a Number argument (defaulted to 1) which controls the smoothness.\nTry smoothing some of the above examples and see what happens!\nEasing functions # The default interpolation used by Hydra on an Array that called .smooth is linear interpolation. You can select a different easing function as follows:\nThe following are the available easing functions:\nlinear: no easing, no acceleration easeInQuad: accelerating from zero velocity easeOutQuad: decelerating to zero velocity easeInOutQuad: acceleration until halfway, then deceleration easeInCubic easeOutCubic easeInOutCubic easeInQuart easeOutQuart easeInOutQuart easeInQuint easeOutQuint easeInOutQuint sin: sinusoidal shape Custom Functions # The other main way of adding dynamic inputs to your sketches is passing functions as arguments. When Hydra takes a function as an argument, what it will do is evaluate it every time it renders a frame. The return of the function will be used as the value for that parameter during that frame render. So you can use a function to simply keep track of a value that you know will change over time, for example, mouse position (which we\u0026rsquo;ll see later).\nThe time variable seen there is a variable pre-declared by Hydra, that stores how much time passed since Hydra started in seconds.\nFunctions used in Hydra don\u0026rsquo;t need to be arrow functions, any no-argument function will do! Make sure your function is returning a Number to avoid errors.\nThe time variable # When you use functions that can take numerical arguments, time will allow you to have their values evolve through\u0026hellip; time. If you multiply time by some value it\u0026rsquo;s as if time goes faster, while dividing while act as making time go slower. For example Math.sin(time*4) will go 4 times faster than Math.sin(time).\nThose users more familiar with mathematics might see this as:\ny(t) = t : ()=\u0026gt;time y(t) = A sin(f t + ph) : ()=\u0026gt;amplitude*Math.sin(freq*time + phase) We recommend getting familiar with some of the methods in the JS built-in Math object. Learn more about it here\nChanging the global speed # You can either slow down or fasten the rate at with time increases via changing the speed variable:\nspeed = 1 // default speed = 2 // twice as fast speed = .5 // half as fast speed = 0 // freezed Note # All of the examples using mouse position to move stuff on the canvas won\u0026rsquo;t work well here, since the canvas doesn\u0026rsquo;t occupy the full size of the screen as in the editor. Take this into account when we use mouse, that the positions are relative to the full webpage and not the canvas. This also means that as you scroll down this guide the y value will get higher and higher.\nMouse interactivity # You can have your visuals react to the position of your mouse (or finger, in touch devices). Hydra has an object called mouse which stores and keeps track of the position of your mouse on the webpage.\nmouse.x \u0026amp; mouse.y # | You can refer to the pixel position of your mouse by calling mouse.x and mouse.y, each one corresponding to the horizontal and vertical coordinates respectively. When we say \u0026lsquo;pixel position\u0026rsquo;, this means that the values you\u0026rsquo;ll find stored in both x and y are represented in pixels. So for mouse.x, this means the amount of pixels from the left edge of your window to the position of your mouse. For mouse.y, this means the amount of pixels between the top end of your screen and the position of your mouse.\nMany times it will be most useful to use values relative to the size of the screen. And also to have values that exist between ranges more reasonable to the hydra functions you\u0026rsquo;re using. For example [-0.5; 0.5] for scrollX and scrollY, [0; 2pi] for rotation, or [0; 1] for general purposes.\nControl anything with your mouse # On Hydra, most values used are pretty small. So it will be way more useful to have the position of the mouse as values from 0 and 1:\nGetting values from 0 to 1 # You can simply multiply by 2*Math.PI to change the range to [0; 2pi]\nMake something follow your mouse # On Hydra, things are placed between 0.5 and -0.5 (left to right, top to bottom). In order for anything to follow your mouse, you\u0026rsquo;ll need to get the position of your mouse between that range:\nGetting values from 0 to ±0.5 from the center # Remember you can name these functions however you prefer.\nAudio reactivity # a.setBins(5) // amount of bins (bands) to separate the audio spectrum noise(2) .modulate(o0,()=\u0026gt;a.fft[1]*.5) // listening to the 2nd band .out() a.setSmooth(.8) // audio reactivity smoothness from 0 to 1, uses linear interpolation a.setScale(8) // loudness upper limit (maps to 0) a.setCutoff(0.1) // loudness from which to start listening to (maps to 0) a.show() // show what hydra\u0026#39;s listening to // a.hide() render(o0) "},{"id":8,"href":"/hydra-blog/docs/learning/guides/textures/","title":"Textures","section":"guides","content":" Textures # by Naoto Hieda\nIn this chapter, we discuss textures or patterns, separately from colors or movements. Most of the snippets have low saturation in order to separate textures from other effects.\nOscillator # osc(freq,sync,offset) is one of the basic sources to create a texture. The first argument determines the frequency (i.e., how packed the stripes are), the second for the sync (i.e., the scroll speed), and the third for the offset, which adds color to the pattern. One cycle of an oscillator in the screen space can be achieved by osc(Math.PI * 2); thus the following example shows 10 cycles:\nFor simplicity, natural numbers are often used as freq or the first argument (e.g., osc(40,0)). The sync parameter is multiplied with time and freq; thus even if sync is unchanged, the larger the frequency, the faster the scroll speed (discussed in motions). offset cycles from 0 to PI*2, which shifts the color.\nBy adding thresh() or posterize(), the oscillator pattern becomes clear stripes. thresh(threshold) literally thresholds the grayscale value; if the pixel\u0026rsquo;s grayscale is brighter than threshold, returns white and else returns black (alpha is preserved). posterize(bins,gamma) thresholds with multiple steps, similar to histogram. pixelate() achieves a similar effect; however, the offset between the bumps of the oscillator and the pixelation bins can create artifacts.\n(render() displays four buffers; o0 on top left, o1 on bottom left, o2 on top right and o3 on bottom right)\nkaleid() with a large number creates circles,\n99 is a magic number; to save character counts (which is essential for live coding), 99 is big enough and only takes 2 characters. However, depending on the effect you want to create, you might need to set a higher number, such as 999, or 1e4.\nYou might have noticed that this sketch is stretched if the window is not square. scale(amount,x,y) can correct the scaling; it scales amount*x to x-axis and amount*y to y-axis. Therefore, scale(1,1,16/9) fits the sketch to 16:9 window, and in general,\nscale(1,1,()=\u0026gt;window.innerWidth/window.innerHeight) adapts the sketch to any size of the window. Notice ()=\u0026gt;, which is an arrow function. If a value is passed to a hydra function (e.g., scale(1,1,window.innerWidth/window.innerHeight)), it will be evaluated only once when ctrl+enter or ctrl+shift+enter is pressed. However, an arrow function is evaluated every frame; thus, it becomes responsive to the window size change. In the rest of the book, a square window is assumed for simplicity. Note that width and height global variables are set when the hydra canvas is initialized, and they will not change according to window resizing.\nkaleid with a small number creates a geometric shape (in the example, an oscillator is combined with kaleid and thresh).\nNoise # noise() is another basic function as a source. A texture is generated based on a variant of Perlin Noise.\nWe will look more into detail in the modulator and arithmetic sections.\nVoronoi # voronoi() is a source to generate a Voronoi diagram.\nShapes # shape(sides,radius,smoothing) generates a polygon with a number of sides set by sides. Nevertheless, it is more than just a polygon - radius changes the size of the shape, and most importantly, smoothing sets gradient of the shape; 1 for fuzzy borders and close to 0 for sharp edges (however, setting to 0 does not work in recent versions). For example, shape(2) is a thick line, which can be scaled to make a thin line.\nor simply,\nBy repeating shape(4) and overlapping them, it gives a grid-like pattern. For convenience, a parameter and a function are stored in JavaScript variables.\nSimilar to kaleid(), shape() with a large number of sides creates a circle. By tweaking the example above, it generates a Polka dot pattern.\nor almost equivalent with (the center of the image will be horizontally shifted)\nThis tiling technique can be used to create a RGB pixel filter. In this example, func is decomposed into R, G, and B channels and overlaid on top of each other.\nScaling # Scaling and difference can also create a periodic texture.\nThis technique can also be applied to a complex texture.\nThe effect can be enhanced by thresh and setting the third argument of voronoi to 0, to have sharp edges. However, a naive implementation will end up in a complete noise (notice that thresh(threshold, tolerance)\u0026rsquo;s tolerance has to be always bigger than 0).\nTo have a desired effect, apply a square mask (before trying the next example, apply solid().out(o0) to clear the buffer).\nThis example can be used together with rotation.\nOr, instead of scale, scrolling functions (scrollX and scrollY) can be used with a feedback loop.\n"},{"id":9,"href":"/hydra-blog/docs/learning/web-editor/","title":"using the web editor","section":"learning","content":" Get to know the browser editor # To get started, open the the hydra web editor in a separate window. Close the top window by clicking the [x] in the top right.\nYou will see some colorful visuals in the background with text on top in the top left of the screen. The text is code that generates the visuals behind it.\nAt the right up corner you will find a toolbar with these buttons: run all code Runs all code on the page (same as typing *ctrl+shift+enter) upload to gallery upload a sketch to Hydra\u0026rsquo;s gallery and create a shorter URL clear all resets the environment and clears text from the editor show random sketch. Loads random sketch examples. Always it is a good way to learn Hydra by studying someone elses code. make random change dices modify values automatically. Try it with some of the sketch examples. show info window show overlay window with help text and links Save your sketch on the internet # When you evaluate the entire code with the run button or with shift + ctrl + enter, Hydra automatically generates a URL that contains the last changes of your sketch. You can copy and paste the url from the URL bar to save it or share it with other people. You can also use the browser back and forward arrows to navigate to earlier versions of your sketch. "},{"id":10,"href":"/hydra-blog/docs/learning/guides/","title":"guides","section":"learning","content":" guides # Deeper dives into hydra topics written by members of the hydra community.\nForeword # why is it called hydra? live coding community and open-source sofware Hydra techniques # Color Modulation Masking and layers Feedback Useful Javascript functions # Extending hydra # Writing custom glsl External libraries # hydra + p5 hydra + THREE.js hydra + AFrame Live performance # "},{"id":11,"href":"/hydra-blog/docs/learning/guides/audio/","title":"Audio","section":"guides","content":" Audio Guide # Reacting to audio # In order to achieve audio reactivity, Hydra makes use of a JavaScript library called Meyda and has a pre-defined object called a to access many of its features. Audio reactivity in Hydra is mainly achieved using an algorithm called Fast Fourier transform. You definitely don\u0026rsquo;t need to know what it is or how it achieves what it does to use it, but you need to understand the following:\nThe audio spectrum # Sound travels through air as a wave, that\u0026rsquo;s fairly common knowledge. This basically means that sound is nothing more than air pressure going up and down through time very fast in weird ways. But we don\u0026rsquo;t experience sound simply as something that goes on and off like a light flickering, many of the sounds we are used to have some sort of frequency or repetition that we interpret as higher or lower pitch. When we listen to a song we can easily differentiate the bass guitar from the singer even if both are playing at the same time. If there are two vocals being sung at the same time, even if by the same person, we can differentiate them because of how high or low they are (also because of timbre, but that doesn\u0026rsquo;t matter at all right now). When we talk about the audio spectrum, we are talking about the many frequencies a sound can cover and we humans can hear. What a fast fourier transform does is basically hear some ongoing sound and interpret how present the sound is on different parts of this spectrum. For example, if we separate the audio spectrum in 3 equal parts and play a drum-kit, the bass drum will have more presence on the lower side of the spectrum, while a hi-hat will surely have most of its presence on the higher third part of the spectrum.\na.show() \u0026amp; a.hide() # We can see what Hydra hears by calling the function a.show(). This will show a small graphic on the lower right corner of the screen. If we want to hide it we can call a.hide()\na.setBins() \u0026amp; a.fft # We can decide into how many parts we want to separate the audio spectrum using the function a.setBins(). As you might\u0026rsquo;ve already guessed, a bin is just a part of the audio spectrum. Try now to use very high values since more bins means more processing and you can go overkill easily. But also, you\u0026rsquo;ll see there usually isn\u0026rsquo;t much need to separate the spectrum into that many parts. To read the current value of a bin we use an Array (a list of variables per se) called a.fft.\nSee the following example:\na.setBins(5) osc(20,.1,2) .saturate(()=\u0026gt;1-a.fft[4]) .rotate(()=\u0026gt;a.fft[0]) .kaleid() .out() See how if you make a deep \u0026ldquo;O\u0026rdquo; sound into the mic, the rotation will be strong and the saturation won\u0026rsquo;t be affected as much. Also try to make a high \u0026ldquo;S\u0026rdquo; sound, you\u0026rsquo;ll see the exact opposite.\nNote how we use brackets to call an element in an Array, and that we start counting from 0.\na.bins \u0026amp; a.prevBins # If you want the raw values from each bin without the mapping from 0 to 1, you can access them via a.bins. You can also use a.prevBins to get the bins from the previous frame.\na.setSmooth() # Sometimes the audio reactive elements react\u0026hellip; too much. You can easily get into strobe territory if you are not careful. You can smooth out the interpretation of the sound using the a.setSmooth() function. A value of 0 will be no smoothing at all, a raw input, while a value of 1 will be so smooth nothing will happen at all. Try evaluating a.setSmooth(.85) above and see how different it looks.\na.setScale() \u0026amp; a.setCutoff() # Each microphone, each sound input, etc, can be quite different in volume and dynamics. If you\u0026rsquo;re on a noisy room, your visuals could react to the noise and that\u0026rsquo;s quite annoying. Or if your mic is too low on volume, your visuals may barely react. If you ran a.show() and look at the graph, you may have noticed there are 2 horizontal lines going across the bins. The lowest one represents the cutoff (guitar players and other musicians out here might know this as a noise gate), this means that the value of the bin will be 0 unless the sound goes above that cutoff. The higher line is the scale, that\u0026rsquo;s where the maximum value of 1 is (again, musicians may want to see this as a limiter with auto-gain). If a given bin goes above the scale value, its value won\u0026rsquo;t go past 1.\na.vol # a.vol will give you the overall volume of the audio input.\na.onBeat() \u0026amp; a.beat # Hydra also has a simple beat detection algorithm. You can change this function to anything you like and it will be executed whenever Hydra detects a beat. The beat detection algorithm uses values from a.vol and compares them with a threshold set at a.beat.\na.beat stores the configuration for the beat detection Hydra uses. It\u0026rsquo;s an Object which most useful parameter is threshold. a.beat.threshold represents the volume to which a.vol will be compared to detect a beat. There\u0026rsquo;s also a.beat.decay which sets the decay after a beat.\nReacting to music # As we\u0026rsquo;ve seen, Hydra takes your microphone as an input, not your desktop audio. Those interested in using a music player or a DAW\u0026rsquo;s output as an audio input will have to delve into virtual audio routing. Users with physical sound interfaces with multiple inputs and outputs might prefer physically routing an output to an input and set that input as the default microphone on Chrome.\nVirtually routing audio to Hydra # TODO\n"}]